{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan_ID               0\n",
      "Gender               13\n",
      "Married               3\n",
      "Dependents           15\n",
      "Education             0\n",
      "Self_Employed        32\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount           22\n",
      "Loan_Amount_Term     14\n",
      "Credit_History       50\n",
      "Property_Area         0\n",
      "Loan_Status           0\n",
      "dtype: int64\n",
      "0\n",
      "No\n",
      "1\n",
      "No\n",
      "2\n",
      "No\n",
      "3\n",
      "No\n",
      "4\n",
      "No\n",
      "5\n",
      "No\n",
      "6\n",
      "Yes\n",
      "7\n",
      "No\n",
      "8\n",
      "No\n",
      "9\n",
      "No\n",
      "10\n",
      "No\n",
      "11\n",
      "No\n",
      "12\n",
      "No\n",
      "13\n",
      "No\n",
      "14\n",
      "No\n",
      "15\n",
      "No\n",
      "16\n",
      "No\n",
      "17\n",
      "No\n",
      "18\n",
      "No\n",
      "19\n",
      "No\n",
      "20\n",
      "No\n",
      "21\n",
      "No\n",
      "22\n",
      "No\n",
      "23\n",
      "No\n",
      "24\n",
      "No\n",
      "25\n",
      "No\n",
      "26\n",
      "No\n",
      "27\n",
      "No\n",
      "28\n",
      "No\n",
      "29\n",
      "No\n",
      "30\n",
      "No\n",
      "31\n",
      "No\n",
      "Loan_ID               0\n",
      "Gender               13\n",
      "Married               3\n",
      "Dependents           15\n",
      "Education             0\n",
      "Self_Employed         0\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount           22\n",
      "Loan_Amount_Term     14\n",
      "Credit_History       50\n",
      "Property_Area         0\n",
      "Loan_Status           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import nan as NaN\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv(\"./data/train.csv\") #Reading the dataset in a dataframe using Pandas\n",
    "\n",
    "print (df_train.isnull().sum())\n",
    "\n",
    "df_train.dtypes\n",
    "\n",
    "def get_categorical_cols(dataframe):\n",
    "    cols = dataframe.columns\n",
    "    num_cols = dataframe._get_numeric_data().columns\n",
    "    categories = (set(cols) - set(num_cols))\n",
    "    return categories\n",
    "        \n",
    "def labelChanger(df_source, rows_to_predict):    \n",
    "    categories = get_categorical_cols(df_source) # we want to change lable only to categorical columns\n",
    "    for categoy in categories:        \n",
    "        lb_make = preprocessing.LabelEncoder()\n",
    "        lb_make.fit(df_source[categoy].tolist())\n",
    "        df_source[categoy] = lb_make.transform(df_source[categoy].tolist())        \n",
    "        rows_to_predict[categoy] = lb_make.transform(rows_to_predict[categoy].tolist())\n",
    "        \n",
    "def get_indices_of_null_records(dataset, attribute):\n",
    "    # get the indices where value na of the arrtibute is null\n",
    "    if dataset[attribute].dtype in ['int64', 'float64']:\n",
    "        indices = [i for i, x in enumerate(dataset[attribute]) if math.isnan(x)]\n",
    "    else:\n",
    "        indices = [i for i, x in enumerate(dataset[attribute]) if x is NaN]\n",
    "    return (indices)\n",
    "\n",
    "def get_records_with_missing_values(dataset, attribute):\n",
    "    indices = get_indices_of_null_records(dataset, attribute)\n",
    "    \n",
    "    rows_missing_value = pd.DataFrame()\n",
    "    chunks=[]\n",
    "    for index in indices:\n",
    "        x = deepcopy(dataset.loc[[index]])\n",
    "        chunks.append(x)\n",
    "        \n",
    "    rows_missing_value = pd.concat(chunks, ignore_index=True)\n",
    "    #rows_to_predict = deepcopy(rows_to_predict)    \n",
    "    return rows_missing_value\n",
    "\n",
    "'''\n",
    "    function gets dataframe and fill NA in every column with the column mode\n",
    "'''\n",
    "def fill_with_mode(dataframe):\n",
    "    for column in dataframe:\n",
    "        dataframe[column].fillna(dataframe[column].mode())\n",
    "        \n",
    "def fill_na_by_prediction(dataset, attribute):\n",
    "    # backup the data\n",
    "    data_backup_copy = deepcopy(dataset)\n",
    "    \n",
    "    # x_data will be dataset with no missing values, the model will be fit on it\n",
    "    x_data = dataset\n",
    "    \n",
    "    # delete columns. ID is irelevant, Load Status we dont have it in test set\n",
    "    x_data.drop('Loan_ID',1, inplace = True)\n",
    "    x_data.drop('Loan_Status',1, inplace = True)\n",
    "    \n",
    "    # save the indecies of missing value records\n",
    "    indecies = get_indices_of_null_records(x_data, attribute)\n",
    "        \n",
    "    # get the rows with missing values into dataframe\n",
    "    rows_with_missing_values = get_records_with_missing_values(x_data, attribute)    \n",
    "    \n",
    "    # remove records with na in x_data. To fit the model we need x_data to be with no NA values\n",
    "    x_data.dropna(how='any', inplace=True)\n",
    "    \n",
    "    # get the target, the column of the attribute\n",
    "    y_target = x_data[attribute]\n",
    "    \n",
    "    # drop the target column from x_data\n",
    "    x_data.drop(attribute, axis = 1, inplace = True)\n",
    "    \n",
    "    # delete the column that we want to predict in rows_with_missing_values\n",
    "    rows_with_missing_values.drop(attribute, 1, inplace = True)\n",
    "    \n",
    "    # If we have NA values in columns that are not the target attribute - we will fill the NA with the mode\n",
    "    fill_with_mode(rows_with_missing_values)\n",
    "\n",
    "    rows_with_missing_values[attribute] = np.nan\n",
    "        \n",
    "    labelChanger(x_data, rows_with_missing_values)\n",
    "    \n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn_clf.fit(x_data, y_target)\n",
    "    \n",
    "    # predict the missing values and place them in the dataset\n",
    "    for index, row in rows_with_missing_values.iterrows():\n",
    "        print index\n",
    "        row.drop(attribute, inplace= True)\n",
    "        try:\n",
    "            prediction = knn_clf.predict([row])[0]\n",
    "            print (prediction)\n",
    "        except:\n",
    "            prediction = data_backup_copy[attribute].mode()[0]\n",
    "            print prediction\n",
    "        \n",
    "        # set  the prediction in the dataset\n",
    "        missing_value_records_index = indecies[index]\n",
    "        data_backup_copy.set_value(missing_value_records_index, attribute, prediction)\n",
    "        \n",
    "    return data_backup_copy\n",
    "\n",
    "df_train = fill_na_by_prediction(df_train, 'Self_Employed')\n",
    "\n",
    "print (df_train.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
